{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforem the source cloud and then draw the point clouds\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    #copy original point clouds\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    #set the color\n",
    "    #source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    #target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    #apply transformation\n",
    "    source_temp.transform(transformation)\n",
    "    #draw the clouds\n",
    "    o3d.visualization.draw_geometries([source_temp,target_temp])\n",
    "    #o3d.visualization.draw_geometries([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down sample the point cloud, recompute new normals, compute fpfh features\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    #use the neighbors recompute the normal\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    #compute the FPFH features\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data, down sample and compute fpfh feature\n",
    "def prepare_dataset(voxel_size):\n",
    "    #load point clouds\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = o3d.io.read_point_cloud(\"/home/yunke/3dv_proj/code/objects/0427/cereal_y/cereal_y_stand.pcd\")\n",
    "    target = o3d.io.read_point_cloud(\"/home/yunke/3dv_proj/code/objects/0427/cereal_y/cereal_y_lie.pcd\")\n",
    "    \n",
    "    #apply an inital transformation\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    #visualize\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    #downsample and compute fpfh feature of the point clouds\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global registration based on RANSAC\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    \n",
    "    #apply RANSAC algorithms for registration:\n",
    "    #pick 4 points,\n",
    "    #pruning with edge length and distance for early stop\n",
    "    result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, distance_threshold,\n",
    "        o3d.registration.TransformationEstimationPointToPoint(False), 4, [\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.registration.RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast global registration\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.registration.registration_fast_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to plane registration\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_fast.transformation,\n",
    "        o3d.registration.TransformationEstimationPointToPlane())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result_original_color(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge overlapped surface\n",
    "def merge_registrated(source, target, voxel_size, result_icp):\n",
    "\n",
    "    #copy point clouds\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(result_icp.transformation)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.normalize_normals()\n",
    "    target_temp.normalize_normals()\n",
    "    \n",
    "    #get points and normals\n",
    "    src_points = np.asarray(source_temp.points)\n",
    "    src_normals = np.asarray(source_temp.normals)\n",
    "    tgt_points = np.asarray(target_temp.points)\n",
    "    tgt_normals = np.asarray(target_temp.normals)\n",
    "    num_tgt = tgt_points.shape[0]\n",
    "    num_tgt_src = tgt_points.shape[0]+src_points.shape[0]\n",
    "    \n",
    "    #compute kdtree:\n",
    "    tgt_src = target_temp+source_temp\n",
    "    tgt_src_points = np.asarray(tgt_src.points)\n",
    "    tgt_src_normals = np.asarray(tgt_src.normals)\n",
    "    tgt_src_colors = np.asarray(tgt_src.colors)\n",
    "    tgt_src_tree = o3d.geometry.KDTreeFlann(tgt_src)\n",
    "    \n",
    "    new_pcd_np = []\n",
    "    new_color_np = []\n",
    "    for i in range(num_tgt_src):\n",
    "        #get neighbors in kdtree\n",
    "        [k,idx,_] = tgt_src_tree.search_radius_vector_3d(tgt_src.points[i], 0.01)  \n",
    "        idx = np.asarray(idx)\n",
    "        #get ones from source or target\n",
    "        if i<num_tgt:\n",
    "            near_src = idx[idx>num_tgt-1]\n",
    "        else:\n",
    "            near_src = idx[idx<num_tgt]\n",
    "        #if none, add to the np\n",
    "        if len(near_src)==0:\n",
    "            new_pcd_np.append(tgt_src_points[i])\n",
    "            new_color_np.append(tgt_src_colors[i])\n",
    "        #else compute nearest one perp to normal drct\n",
    "        else:\n",
    "            cur_point = tgt_src_points[i]\n",
    "            cur_normal = tgt_src_normals[i]\n",
    "            \n",
    "            near_src_points = tgt_src_points[near_src]\n",
    "            near_src_vec = near_src_points-cur_point\n",
    "            near_src_dist = np.linalg.norm(near_src_vec-np.dot(np.dot(near_src_vec,cur_normal.reshape((3,1))),cur_normal.reshape((1,3))),axis=1)\n",
    "            nearest_idx = near_src[np.argmin(near_src_dist)]\n",
    "            #dot the two normals\n",
    "            nearest_normal = tgt_src_normals[nearest_idx]\n",
    "            nearest_point = tgt_src_points[nearest_idx]\n",
    "            dot_normal = np.dot(cur_normal,nearest_normal)\n",
    "            #if angle small,get one new point\n",
    "            if dot_normal>0.75 or dot_normal<-0.75:\n",
    "                # only compute once\n",
    "                if i<num_tgt:\n",
    "                    new_pcd_np.append(0.5*(cur_point+nearest_point))\n",
    "                    new_color_np.append(0.5*(tgt_src_colors[i]+tgt_src_colors[nearest_idx]))\n",
    "            #else add original point\n",
    "            else:\n",
    "                new_pcd_np.append(cur_point)\n",
    "                new_color_np.append(tgt_src_colors[i])\n",
    "    \n",
    "    new_pcd_np = np.asarray(new_pcd_np)\n",
    "    new_color_np = np.asarray(new_color_np)\n",
    "    #build point cloud\n",
    "    final_pcd = o3d.geometry.PointCloud()\n",
    "    final_pcd.points = o3d.utility.Vector3dVector(new_pcd_np)\n",
    "    final_pcd.colors = o3d.utility.Vector3dVector(new_color_np)\n",
    "    final_pcd.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    #merge\n",
    "    return final_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.007.\n",
      ":: Estimate normal with search radius 0.014.\n",
      ":: Compute FPFH feature with search radius 0.035.\n",
      ":: Downsample with a voxel size 0.007.\n",
      ":: Estimate normal with search radius 0.014.\n",
      ":: Compute FPFH feature with search radius 0.035.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.007,\n",
      "   we use a liberal distance threshold 0.011.\n",
      "Global registration took 3.342 sec.\n",
      "\n",
      "registration::RegistrationResult with fitness=8.611017e-01, inlier_rmse=5.126419e-03, and correspondence_set size of 5065\n",
      "Access transformation to get result.\n",
      ":: Apply fast global registration with distance threshold 0.004\n",
      "Fast global registration took 0.092 sec.\n",
      "\n",
      "registration::RegistrationResult with fitness=2.874872e-01, inlier_rmse=2.649722e-03, and correspondence_set size of 1691\n",
      "Access transformation to get result.\n",
      ":: Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. This time we use a strict\n",
      "   distance threshold 0.003.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.007  # means 5cm for the dataset\n",
    "\n",
    "#down sample, compute fpfh of the data\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = \\\n",
    "        prepare_dataset(voxel_size)\n",
    "\n",
    "\n",
    "#global registration using ransac\n",
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_ransac)\n",
    "\n",
    "\n",
    "# #draw the result\n",
    "draw_registration_result_original_color(source_down, target_down,\n",
    "                         result_ransac.transformation)\n",
    "\n",
    "#fast global registration\n",
    "start = time.time()\n",
    "result_fast=execute_fast_global_registration(source_down, target_down,\n",
    "                                             source_fpfh, target_fpfh,\n",
    "                                             voxel_size)\n",
    "                         \n",
    "print(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_fast)\n",
    "draw_registration_result_original_color(source_down, target_down,\n",
    "                         result_fast.transformation)\n",
    "    \n",
    "#local refinement\n",
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh,\n",
    "                                 voxel_size)\n",
    "# print(result_icp)\n",
    "draw_registration_result_original_color(source, target, result_icp.transformation)\n",
    "\n",
    "\n",
    "source_temp = copy.deepcopy(source)\n",
    "target_temp = copy.deepcopy(target)\n",
    "source_temp.transform(result_icp.transformation)\n",
    "final_without_refine = target_temp+source_temp\n",
    "o3d.visualization.draw_geometries([final_without_refine])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare original and new points of objects\n",
    "final_down=final_without_refine.voxel_down_sample(voxel_size*0.1)\n",
    "o3d.visualization.draw_geometries([final_down])\n",
    "final_pcd = merge_registrated(source, target, voxel_size, result_icp)\n",
    "\n",
    "o3d.visualization.draw_geometries([final_pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

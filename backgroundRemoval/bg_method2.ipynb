{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforem the source cloud and then draw the point clouds\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    #copy original point clouds\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    #set the color\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    #apply transformation\n",
    "    source_temp.transform(transformation)\n",
    "    #draw the clouds\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down sample the point cloud, recompute new normals, compute fpfh features\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    #use the neighbors recompute the normal\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    #compute the FPFH features\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data, down sample and compute fpfh feature\n",
    "def prepare_dataset(voxel_size):\n",
    "    #load point clouds\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = o3d.io.read_point_cloud(\"badslam_scan0422/good3_bg.ply\")\n",
    "    target = o3d.io.read_point_cloud(\"badslam_scan0422/cap/cap1.ply\")\n",
    "    \n",
    "    #apply an inital transformation\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    #visualize\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    #downsample and compute fpfh feature of the point clouds\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global registration based on RANSAC\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    \n",
    "    #apply RANSAC algorithms for registration:\n",
    "    #pick 4 points,\n",
    "    #pruning with edge length and distance for early stop\n",
    "    result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, distance_threshold,\n",
    "        o3d.registration.TransformationEstimationPointToPoint(False), 4, [\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.registration.RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast global registration\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.registration.registration_fast_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to plane registration\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_fast.transformation,\n",
    "        o3d.registration.TransformationEstimationPointToPlane())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "Global registration took 0.582 sec.\n",
      "\n",
      "registration::RegistrationResult with fitness=8.389843e-01, inlier_rmse=3.328656e-02, and correspondence_set size of 5617\n",
      "Access transformation to get result.\n",
      ":: Apply fast global registration with distance threshold 0.025\n",
      "Fast global registration took 0.228 sec.\n",
      "\n",
      "registration::RegistrationResult with fitness=5.044063e-01, inlier_rmse=1.832058e-02, and correspondence_set size of 3377\n",
      "Access transformation to get result.\n",
      ":: Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. This time we use a strict\n",
      "   distance threshold 0.020.\n",
      "registration::RegistrationResult with fitness=6.417527e-01, inlier_rmse=6.634905e-03, and correspondence_set size of 152535\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.05  # means 5cm for the dataset\n",
    "\n",
    "#down sample, compute fpfh of the data\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = \\\n",
    "        prepare_dataset(voxel_size)\n",
    "\n",
    "#global registration using ransac\n",
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_ransac)\n",
    "\n",
    "\n",
    "#draw the result\n",
    "#draw_registration_result(source_down, target_down,\n",
    "#                         result_ransac.transformation)\n",
    "\n",
    "#fast global registration\n",
    "start = time.time()\n",
    "result_fast = execute_fast_global_registration(source_down, target_down,\n",
    "                                               source_fpfh, target_fpfh,\n",
    "                                               voxel_size)\n",
    "print(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_fast)\n",
    "draw_registration_result(source_down, target_down,\n",
    "                         result_fast.transformation)\n",
    "    \n",
    "#local refinement\n",
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh,\n",
    "                                 voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "###cluster/segmentation -> segment out planes-> cluster again -> compute ratio of outliers of clusters-> find best clusters\n",
    "target_br = target\n",
    "##cluster the point cloud:\n",
    "init_cluster = np.asarray(target_br.cluster_dbscan(voxel_size*0.65, 100, print_progress=False))\n",
    "print(init_cluster)\n",
    "num_cls = max(init_cluster)+1\n",
    "\n",
    "clusters_points = []\n",
    "clusters_points_visusal = []\n",
    "clusters_ind = []\n",
    "target_ind = np.arange(0,np.size(init_cluster),1)\n",
    "for cluster in range(max(init_cluster)+1):\n",
    "    #get point cloud index of certain cluster\n",
    "    cur_cluster_ind = target_ind[init_cluster==cluster]\n",
    "    clusters_ind.append(cur_cluster_ind)\n",
    "    #get point cloud of certain cluster\n",
    "    cur_cluster_points = target.select_down_sample(cur_cluster_ind)\n",
    "    clusters_points.append(cur_cluster_points)\n",
    "    #visualization\n",
    "    cur_cluster_temp = copy.deepcopy(cur_cluster_points)\n",
    "    temp_value = np.random.rand(1,3)\n",
    "    cur_cluster_temp.paint_uniform_color([temp_value[0][0], temp_value[0][1], temp_value[0][2]])\n",
    "    clusters_points_visusal.append(cur_cluster_temp)\n",
    "\n",
    "#visualization\n",
    "#o3d.visualization.draw_geometries(clusters_points)\n",
    "flat_clusters_ind = np.concatenate(clusters_ind,axis=0)\n",
    "target_cluster = target_br.select_down_sample(flat_clusters_ind)\n",
    "o3d.visualization.draw_geometries([target_cluster])\n",
    "o3d.visualization.draw_geometries(clusters_points_visusal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "##segment out planes in each cluster\n",
    "\n",
    "clusters_plane = []\n",
    "for n_cls in range(num_cls):\n",
    "    #get size of the cluster\n",
    "    num_points = np.size(clusters_ind[n_cls])\n",
    "    #segment a plane in the cluster\n",
    "    plane,points_on_plane = clusters_points[n_cls].segment_plane(0.01,30,1000)\n",
    "    #get index of plane points\n",
    "    inds_plane = clusters_ind[n_cls][points_on_plane]\n",
    "    \n",
    "    #jurge whether the plane is from the object or from the desk.\n",
    "    #1. get ind without plane\n",
    "    inds_not_on_plane = np.setdiff1d(clusters_ind[n_cls],inds_plane)\n",
    "    #2. get points and points without plane.\n",
    "    post = target.select_down_sample(inds_not_on_plane)\n",
    "    pre_points = np.asarray(clusters_points[n_cls].points)\n",
    "    post_points = np.asarray(post.points)\n",
    "    #3. calculate varience of normalized directions\n",
    "    pre_mean_point=np.mean(pre_points,axis = 0)\n",
    "    #print(pre_mean_point)\n",
    "    post_mean_point = np.mean(post_points,axis = 0)\n",
    "    pre_drct = (pre_points-pre_mean_point)/np.linalg.norm(pre_points-pre_mean_point,axis=1)[:,None]\n",
    "    post_drct = (post_points-post_mean_point)/np.linalg.norm(post_points-post_mean_point,axis=1)[:,None]\n",
    "    pre_var = np.sum(np.var(pre_drct))\n",
    "    post_var = np.sum(np.var(post_drct))\n",
    "    #4. judge and record: after segmentation become two objects, or itself is a plane\n",
    "    cluster_n=0\n",
    "    if not np.size(np.asarray(post.cluster_dbscan(voxel_size*0.65, 100, print_progress=False)))==0:\n",
    "        cluster_n = np.max(np.asarray(post.cluster_dbscan(voxel_size*0.65, 100, print_progress=False)))\n",
    "    #print(cluster_n)\n",
    "    #if pre_var<post_var or np.size(inds_plane)>num_points*0.8 or cluster_n>0:\n",
    "    clusters_plane.append(inds_plane)\n",
    "\n",
    "#plane points ind\n",
    "flat_clusters_plane = np.concatenate(clusters_plane,axis=0)\n",
    "\n",
    "#get remaining points index\n",
    "flat_cls_ind_no_plane = np.setdiff1d(flat_clusters_ind,flat_clusters_plane)\n",
    "\n",
    "target_plane = target_br.select_down_sample(flat_clusters_plane)\n",
    "target_cluster_no_plane = target_br.select_down_sample(flat_cls_ind_no_plane)\n",
    "\n",
    "#visualization\n",
    "o3d.visualization.draw_geometries([target_plane])\n",
    "o3d.visualization.draw_geometries([target_cluster_no_plane])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "##cluster again\n",
    "target_br_new = target_cluster_no_plane\n",
    "\n",
    "#cluster the point cloud:\n",
    "cluster_new = np.asarray(target_br_new.cluster_dbscan(voxel_size*0.45, 100, print_progress=False))\n",
    "print(cluster_new)\n",
    "num_cls_new = max(cluster_new)+1\n",
    "\n",
    "clusters_points_new = []\n",
    "clusters_points_visusal_new = []\n",
    "clusters_ind_new = []\n",
    "for cluster in range(max(cluster_new)+1):\n",
    "    #get point cloud index of certain cluster\n",
    "    cur_cluster_ind_new = flat_cls_ind_no_plane[cluster_new==cluster]\n",
    "    clusters_ind_new.append(cur_cluster_ind_new)\n",
    "    #get point cloud of certain cluster\n",
    "    cur_cluster_points_new = target_br.select_down_sample(cur_cluster_ind_new)\n",
    "    clusters_points_new.append(cur_cluster_points_new)\n",
    "    cur_cluster_temp = copy.deepcopy(cur_cluster_points_new)\n",
    "    temp_value = np.random.rand(1,3)\n",
    "    cur_cluster_temp.paint_uniform_color([temp_value[0][0], temp_value[0][1], temp_value[0][2]])\n",
    "    clusters_points_visusal_new.append(cur_cluster_temp)\n",
    "\n",
    "#visualization\n",
    "#o3d.visualization.draw_geometries(clusters_points)\n",
    "flat_clusters_ind_new = np.concatenate(clusters_ind_new,axis=0)\n",
    "target_cluster_new = target_br.select_down_sample(flat_clusters_ind_new)\n",
    "o3d.visualization.draw_geometries([target_cluster_new])\n",
    "o3d.visualization.draw_geometries(clusters_points_visusal_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0.3202723335263922]\n",
      "[0.008762072097966813]\n",
      "[0.2596518017900625]\n",
      "[0.5692912203812746]\n",
      "[24593]\n",
      "1\n",
      "[0.9984548448745578]\n"
     ]
    }
   ],
   "source": [
    "##choose the object from clusters\n",
    "#mean of all points:\n",
    "mean_coordinate = np.mean(np.asarray(target_br.points))\n",
    "#get outliers\n",
    "cor_ind = np.asarray(result_icp.correspondence_set)\n",
    "out_ind = np.setdiff1d(target_ind,cor_ind[:,1])\n",
    "o3d.visualization.draw_geometries([target_br.select_down_sample(out_ind)])\n",
    "\n",
    "clusters_candidate = []\n",
    "clusters_cand_points = []\n",
    "clusters_scores = []\n",
    "clusters_var_points = []\n",
    "clusters_var_normals = []\n",
    "clusters_distance = []\n",
    "clusters_ratio = []\n",
    "clusters_number = []\n",
    "t=0\n",
    "#compute ratio of each cluster\n",
    "for cluster in range(max(cluster_new)+1):\n",
    "    #number of outliers\n",
    "    cur_cluster_ind = clusters_ind_new[cluster]\n",
    "    num_outliers = np.sum(np.size(np.intersect1d(cur_cluster_ind,out_ind)))\n",
    "    \n",
    "    #ratio of outliers\n",
    "    ratio_outliers = num_outliers/np.size(cur_cluster_ind)\n",
    "    #number of elements\n",
    "    num_element = np.size(cur_cluster_ind)\n",
    "    cur_cluster_points = clusters_points_new[cluster]\n",
    "    #variance (defined) of points\n",
    "    points = np.asarray(cur_cluster_points.points)\n",
    "    mean_points=np.mean(points,axis=0)\n",
    "    points_distance = np.linalg.norm(points-mean_points,axis=1)\n",
    "    points_dist_mean = np.mean(points_distance)\n",
    "    points_dist_var = np.var(points_distance)\n",
    "    disperse = points_dist_var/points_dist_mean\n",
    "    #variance of normal        \n",
    "    normals = np.asarray(cur_cluster_points.normals)\n",
    "    var_normals = np.sum(np.var(normals))\n",
    "    #difference from center?\n",
    "    distance = np.linalg.norm(mean_points-mean_coordinate)\n",
    "    #variance of direction\n",
    "    drct = (points-mean_points)/np.linalg.norm(points-mean_points,axis=1)[:,None]\n",
    "    var_drct = np.mean(np.var(drct,axis=0))\n",
    "    \n",
    "    if ratio_outliers>0.96 and num_element>2000 and num_element<40000 and var_normals>0.15 and points_dist_mean>0.05 and points_dist_mean<0.30:         \n",
    "        if t==0:\n",
    "            best_cluster = cluster\n",
    "            best_score = -100\n",
    "            t=1\n",
    "            \n",
    "        \n",
    "        score = var_drct-disperse\n",
    "        #-disperse-distance\n",
    "        clusters_scores.append(score)\n",
    "        if score>best_score:\n",
    "            best_cluster = cluster\n",
    "            best_score = score\n",
    "        \n",
    "        clusters_candidate.append(cluster)\n",
    "        clusters_cand_points.append(target_br.select_down_sample(clusters_ind_new[cluster]))\n",
    "        clusters_var_points.append(disperse)\n",
    "        clusters_var_normals.append(var_normals)\n",
    "        clusters_distance.append(distance)\n",
    "        clusters_number.append(num_element)\n",
    "        clusters_ratio.append(ratio_outliers)\n",
    "\n",
    "print(clusters_candidate)\n",
    "print(clusters_scores)\n",
    "print(clusters_var_points)\n",
    "print(clusters_var_normals)\n",
    "print(clusters_distance)\n",
    "print(clusters_number)\n",
    "print(best_cluster)\n",
    "print(clusters_ratio)\n",
    "\n",
    "max_cluster_ind = clusters_ind_new[best_cluster]\n",
    "object_cloud = target_br.select_down_sample(max_cluster_ind)\n",
    "o3d.visualization.draw_geometries(clusters_cand_points)\n",
    "o3d.visualization.draw_geometries([object_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"objects/cap1_object.pcd\",object_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforem the source cloud and then draw the point clouds\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    #copy original point clouds\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    #set the color\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    #apply transformation\n",
    "    source_temp.transform(transformation)\n",
    "    #draw the clouds\n",
    "    o3d.visualization.draw_geometries([source])\n",
    "    o3d.visualization.draw_geometries([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down sample the point cloud, recompute new normals, compute fpfh features\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    #use the neighbors recompute the normal\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    #compute the FPFH features\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data, down sample and compute fpfh feature\n",
    "def prepare_dataset(voxel_size):\n",
    "    #load point clouds\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = o3d.io.read_point_cloud(\"badslam_scan0422/good3_bg.ply\")\n",
    "    target = o3d.io.read_point_cloud(\"badslam_scan0422/ball/ball.ply\")\n",
    "    \n",
    "    #apply an inital transformation\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    #visualize\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    #downsample and compute fpfh feature of the point clouds\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global registration based on RANSAC\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    \n",
    "    #apply RANSAC algorithms for registration:\n",
    "    #pick 4 points,\n",
    "    #pruning with edge length and distance for early stop\n",
    "    result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, distance_threshold,\n",
    "        o3d.registration.TransformationEstimationPointToPoint(False), 4, [\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.registration.RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast global registration\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.registration.registration_fast_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to plane registration\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_fast.transformation,\n",
    "        o3d.registration.TransformationEstimationPointToPlane())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "Global registration took 0.654 sec.\n",
      "\n",
      "registration::RegistrationResult with fitness=8.993279e-01, inlier_rmse=3.114507e-02, and correspondence_set size of 6021\n",
      "Access transformation to get result.\n",
      ":: Apply fast global registration with distance threshold 0.025\n",
      "Fast global registration took 0.287 sec.\n",
      "\n",
      "registration::RegistrationResult with fitness=4.800597e-01, inlier_rmse=1.815831e-02, and correspondence_set size of 3214\n",
      "Access transformation to get result.\n",
      ":: Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. This time we use a strict\n",
      "   distance threshold 0.020.\n",
      "registration::RegistrationResult with fitness=6.641059e-01, inlier_rmse=7.206955e-03, and correspondence_set size of 157848\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.05  # means 5cm for the dataset\n",
    "\n",
    "#down sample, compute fpfh of the data\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = \\\n",
    "        prepare_dataset(voxel_size)\n",
    "\n",
    "#global registration using ransac\n",
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_ransac)\n",
    "\n",
    "\n",
    "#draw the result\n",
    "#draw_registration_result(source_down, target_down,\n",
    "#                         result_ransac.transformation)\n",
    "\n",
    "#fast global registration\n",
    "start = time.time()\n",
    "result_fast = execute_fast_global_registration(source_down, target_down,\n",
    "                                               source_fpfh, target_fpfh,\n",
    "                                               voxel_size)\n",
    "print(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "print(result_fast)\n",
    "#draw_registration_result(source_down, target_down,\n",
    "#                         result_fast.transformation)\n",
    "    \n",
    "#local refinement\n",
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh,\n",
    "                                 voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59423 260484]\n",
      " [ 59424 198584]\n",
      " [ 59425 104463]\n",
      " ...\n",
      " [ 59419  73594]\n",
      " [ 59420 292816]\n",
      " [ 59421 321828]]\n",
      "geometry::PointCloud with 254180 points.\n",
      "(254180,)\n"
     ]
    }
   ],
   "source": [
    "#outlier->segment plane->cluster->find object with variance of normal and position\n",
    "#select ouliers from icp algorithms\n",
    "threshold = voxel_size*1\n",
    "\n",
    "#get points with correspondence\n",
    "cor_ind = np.asarray(result_icp.correspondence_set)\n",
    "print(cor_ind)\n",
    "target_out = target.select_down_sample(cor_ind[:,1],invert=True)\n",
    "print(target_out)\n",
    "o3d.visualization.draw_geometries([target_out])\n",
    "##compute outlier distance\n",
    "out_dist = np.asarray(target_out.compute_point_cloud_distance(source))\n",
    "\n",
    "l_cor_s = np.shape(out_dist)\n",
    "l = l_cor_s[0]\n",
    "print(l_cor_s)\n",
    "\n",
    "#select outlier index\n",
    "out_index = np.arange(0,l,1)\n",
    "out_list = out_index[out_dist>threshold]\n",
    "target_out = target_out.select_down_sample(out_list)\n",
    "o3d.visualization.draw_geometries([target_out])\n",
    "\n",
    "\n",
    "#cluster\n",
    "cluster_result = target_out.cluster_dbscan(voxel_size*0.35, 20, print_progress=False)\n",
    "cluster_np = np.asarray(cluster_result)\n",
    "\n",
    "clusters_points = []\n",
    "clusters_points_visusal = []\n",
    "clusters_ind = []\n",
    "clusters_candidate = []\n",
    "clusters_cand_points = []\n",
    "clusters_scores = []\n",
    "clusters_var_points = []\n",
    "clusters_var_normals = []\n",
    "clusters_distance = []\n",
    "clusters_ratio = []\n",
    "clusters_number = []\n",
    "t=0\n",
    "target_ind = np.arange(0,np.size(cluster_np),1)\n",
    "for cluster in range(max(cluster_np)+1):\n",
    "    #get point cloud index of certain cluster\n",
    "    cur_cluster_ind = target_ind[cluster_np==cluster]\n",
    "    clusters_ind.append(cur_cluster_ind)\n",
    "    #get point cloud of certain cluster\n",
    "    cur_cluster_points = target_out.select_down_sample(cur_cluster_ind)\n",
    "    clusters_points.append(cur_cluster_points)\n",
    "    #visualization\n",
    "    cur_cluster_temp = copy.deepcopy(cur_cluster_points)\n",
    "    temp_value = np.random.rand(1,3)\n",
    "    cur_cluster_temp.paint_uniform_color([temp_value[0][0], temp_value[0][1], temp_value[0][2]])\n",
    "    clusters_points_visusal.append(cur_cluster_temp)\n",
    "\n",
    "o3d.visualization.draw_geometries(clusters_points_visusal)\n",
    "flat_clusters_ind = np.concatenate(clusters_ind,axis=0)\n",
    "target_cluster = target_out.select_down_sample(flat_clusters_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "##segment out planes in each cluster\n",
    "o3d.visualization.draw_geometries([clusters_points[6]])\n",
    "num_cls = np.max(cluster_np)+1\n",
    "print(num_cls)\n",
    "clusters_plane = []\n",
    "for n_cls in range(num_cls):\n",
    "    #get size of the cluster\n",
    "#     print(n_cls)\n",
    "    num_points = np.size(clusters_ind[n_cls])\n",
    "    #segment a plane in the cluster\n",
    "    plane,points_on_plane = clusters_points[n_cls].segment_plane(0.007,4,1000)\n",
    "#     print(\"segment_plane\")\n",
    "    #get index of plane points\n",
    "    inds_plane = clusters_ind[n_cls][points_on_plane]\n",
    "#     print(\"inds_plnae\")\n",
    "    #jurge whether the plane is from the object or from the desk.\n",
    "    #1. get ind without plane\n",
    "    inds_not_on_plane = np.setdiff1d(clusters_ind[n_cls],inds_plane)\n",
    "    #2. get points and points without plane.\n",
    "    post = target_out.select_down_sample(inds_not_on_plane)\n",
    "    pre_points = np.asarray(clusters_points[n_cls].points)\n",
    "    post_points = np.asarray(post.points)\n",
    "    #3. calculate varience of normalized directions\n",
    "    pre_mean_point=np.mean(pre_points,axis = 0)\n",
    "    #print(pre_mean_point)\n",
    "    post_mean_point = np.mean(post_points,axis = 0)\n",
    "    pre_drct = (pre_points-pre_mean_point)/np.linalg.norm(pre_points-pre_mean_point,axis=1)[:,None]\n",
    "    post_drct = (post_points-post_mean_point)/np.linalg.norm(post_points-post_mean_point,axis=1)[:,None]\n",
    "    pre_var = np.sum(np.var(pre_drct))\n",
    "    post_var = np.sum(np.var(post_drct))\n",
    "#     print(\"post_pre\")\n",
    "    #4. judge and record: after segmentation become two objects, or itself is a plane\n",
    "    cluster_n=0\n",
    "    \n",
    "    if not np.size(post_points,0)==0:\n",
    "#         print(np.size(post_points,0))\n",
    "        post_cluster = post.cluster_dbscan(voxel_size*0.5, 10, print_progress=False)\n",
    "        #get cluster\n",
    "        post_cluster = np.asarray(post_cluster)\n",
    "        if not np.size(post_cluster)==0:        \n",
    "#             print(post_cluster)\n",
    "            cluster_n = max(post_cluster)\n",
    "#             print(\"cluster_n\")\n",
    "                \n",
    "    #print(cluster_n)\n",
    "    if pre_var<post_var or np.size(inds_plane)>num_points*0.8 or cluster_n>0:\n",
    "        clusters_plane.append(inds_plane)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane points ind\n",
    "flat_clusters_plane = np.concatenate(clusters_plane,axis=0)\n",
    "\n",
    "#get remaining points index\n",
    "flat_cls_ind_no_plane = np.setdiff1d(flat_clusters_ind,flat_clusters_plane)\n",
    "\n",
    "target_plane = target_out.select_down_sample(flat_clusters_plane)\n",
    "target_cluster_no_plane = target_out.select_down_sample(flat_cls_ind_no_plane)\n",
    "\n",
    "#visualization\n",
    "o3d.visualization.draw_geometries([target_plane])\n",
    "o3d.visualization.draw_geometries([target_cluster_no_plane])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "#cluster the point cloud:\n",
    "cluster_new = np.asarray(target_cluster_no_plane.cluster_dbscan(voxel_size*0.15, 10, print_progress=False))\n",
    "print(cluster_new)\n",
    "num_cls_new = max(cluster_new)+1\n",
    "\n",
    "clusters_points_new = []\n",
    "clusters_points_visusal_new = []\n",
    "clusters_ind_new = []\n",
    "for cluster in range(max(cluster_new)+1):\n",
    "    #get point cloud index of certain cluster\n",
    "    cur_cluster_ind_new = flat_cls_ind_no_plane[cluster_new==cluster]\n",
    "    clusters_ind_new.append(cur_cluster_ind_new)\n",
    "    #get point cloud of certain cluster\n",
    "    cur_cluster_points_new = target_out.select_down_sample(cur_cluster_ind_new)\n",
    "    clusters_points_new.append(cur_cluster_points_new)\n",
    "    cur_cluster_temp = copy.deepcopy(cur_cluster_points_new)\n",
    "    temp_value = np.random.rand(1,3)\n",
    "    cur_cluster_temp.paint_uniform_color([temp_value[0][0], temp_value[0][1], temp_value[0][2]])\n",
    "    clusters_points_visusal_new.append(cur_cluster_temp)\n",
    "\n",
    "#visualization\n",
    "#o3d.visualization.draw_geometries(clusters_points)\n",
    "flat_clusters_ind_new = np.concatenate(clusters_ind_new,axis=0)\n",
    "target_cluster_new = target_out.select_down_sample(flat_clusters_ind_new)\n",
    "o3d.visualization.draw_geometries([target_cluster_new])\n",
    "o3d.visualization.draw_geometries(clusters_points_visusal_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 30, 42]\n",
      "[0.9904927695744757, 0.9790210826254553, 0.9552921535298503, 0.9796021592118157, 0.9843441520772188, 0.9879471243560624]\n",
      "[0.0030363915813062118, 0.015036026577830004, 0.023425409518284247, 0.011249714182243764, 0.014366890281823995, 0.011458718548097453]\n",
      "[0.2919404149942897, 0.31304978170696174, 0.3152888237367161, 0.3330235562165256, 0.3253061142396513, 0.3239057151675743]\n",
      "[0.2944956975131145, 0.12338283779399473, 0.35133597911977144, 0.47065555354115124, 0.4361301921732689, 0.5429392033668641]\n",
      "[23479, 12594, 19467, 2670, 1199, 2341]\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#find the cluster with most variance of normals and least variance of position\n",
    "mean_coordinate = np.mean(np.asarray(target_out.points))\n",
    "for cluster in range(max(cluster_new)+1):\n",
    "    cur_cluster_ind = clusters_ind_new[cluster]\n",
    "\n",
    "    #number of elements\n",
    "    num_element = np.size(cur_cluster_ind)\n",
    "    cur_cluster_points = clusters_points_new[cluster]\n",
    "    #variance (defined) of points\n",
    "    points = np.asarray(cur_cluster_points.points)\n",
    "    mean_points=np.mean(points,axis=0)\n",
    "    points_distance = np.linalg.norm(points-mean_points,axis=1)\n",
    "    points_dist_mean = np.mean(points_distance)\n",
    "    points_dist_var = np.var(points_distance)\n",
    "    disperse = points_dist_var/points_dist_mean\n",
    "    #variance of directions\n",
    "    #print(mean_points.shape)\n",
    "    points_drct = (points-mean_points)/np.linalg.norm(points-mean_points,axis=1)[:,None]\n",
    "    #print(np.linalg.norm(points-mean_points,axis=1).shape)\n",
    "    drct_var = np.sum(np.var(points_drct,axis=0))\n",
    "    #print(np.var(points_drct,axis=0).shape)\n",
    "    #variance of normal        \n",
    "    normals = np.asarray(cur_cluster_points.normals)\n",
    "    var_normals = np.sum(np.var(normals))\n",
    "    #difference from center?\n",
    "    distance = np.linalg.norm(mean_points-mean_coordinate)\n",
    "        \n",
    "    \n",
    "    if num_element>1000 and num_element<40000 and var_normals>0.25:         \n",
    "        if t==0:\n",
    "            best_cluster = cluster\n",
    "            best_score = -100\n",
    "            t=1\n",
    "            \n",
    "        \n",
    "        score = drct_var-disperse\n",
    "        clusters_scores.append(score)\n",
    "        if score>best_score:\n",
    "            best_cluster = cluster\n",
    "            best_score = score\n",
    "        \n",
    "        clusters_candidate.append(cluster)\n",
    "        clusters_cand_points.append(target_out.select_down_sample(clusters_ind_new[cluster]))\n",
    "        clusters_var_points.append(disperse)\n",
    "        clusters_var_normals.append(var_normals)\n",
    "        clusters_distance.append(distance)\n",
    "        clusters_number.append(num_element)\n",
    "        \n",
    "print(clusters_candidate)\n",
    "print(clusters_scores)\n",
    "print(clusters_var_points)\n",
    "print(clusters_var_normals)\n",
    "print(clusters_distance)\n",
    "print(clusters_number)\n",
    "print(best_cluster)\n",
    "print(clusters_ratio)       \n",
    "        \n",
    "max_cluster_ind = clusters_ind_new[best_cluster]\n",
    "object_cloud = target_out.select_down_sample(max_cluster_ind)\n",
    "o3d.visualization.draw_geometries(clusters_cand_points)\n",
    "o3d.visualization.draw_geometries([object_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(\"objects/ball_object.pcd\",object_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
